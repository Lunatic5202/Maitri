{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14063869,"sourceType":"datasetVersion","datasetId":8951702}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport cv2\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:31.764517Z","iopub.execute_input":"2025-12-09T08:41:31.765082Z","iopub.status.idle":"2025-12-09T08:41:42.451936Z","shell.execute_reply.started":"2025-12-09T08:41:31.765057Z","shell.execute_reply":"2025-12-09T08:41:42.451325Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Filtering out unwanted classes.","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/fer2013-dataset/fer2013.csv\"\ndf = pd.read_csv(DATA_PATH)\n# Keep only required emotions\nselected_classes = [0, 1, 3, 4, 6]   # angry, disgust, happy, sad, neutral\n\ndf = df[df['emotion'].isin(selected_classes)]\ndf = df.reset_index(drop=True)\n\nprint(\"Total samples after filtering:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:42.453442Z","iopub.execute_input":"2025-12-09T08:41:42.453961Z","iopub.status.idle":"2025-12-09T08:41:47.694875Z","shell.execute_reply.started":"2025-12-09T08:41:42.453941Z","shell.execute_reply":"2025-12-09T08:41:47.694256Z"}},"outputs":[{"name":"stdout","text":"Total samples after filtering: 26764\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"This class defines a custom PyTorch dataset that reads FER2013 images from a DataFrame, converts them to 3‑channel 224×224 images, optionally applies transforms, and returns them with numeric labels.","metadata":{}},{"cell_type":"code","source":"class FERDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        pixels = np.array(row['pixels'].split(), dtype=\"uint8\")\n        image = pixels.reshape(48, 48)\n        \n        # Convert grayscale to RGB (ResNet needs 3 channels)\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n\n        # Resize to 224x224 for ResNet requirements\n        image = cv2.resize(image, (224, 224))\n\n        image = Image.fromarray(image)\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = selected_classes.index(row['emotion'])\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:47.695605Z","iopub.execute_input":"2025-12-09T08:41:47.695799Z","iopub.status.idle":"2025-12-09T08:41:47.701751Z","shell.execute_reply.started":"2025-12-09T08:41:47.695783Z","shell.execute_reply":"2025-12-09T08:41:47.701052Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Test and Train Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['emotion'])\n\nprint(len(train_df), len(val_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:47.702394Z","iopub.execute_input":"2025-12-09T08:41:47.702562Z","iopub.status.idle":"2025-12-09T08:41:48.326879Z","shell.execute_reply.started":"2025-12-09T08:41:47.702548Z","shell.execute_reply":"2025-12-09T08:41:48.326120Z"}},"outputs":[{"name":"stdout","text":"24087 2677\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Transformation before feeding it to the model.","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:48.328560Z","iopub.execute_input":"2025-12-09T08:41:48.328939Z","iopub.status.idle":"2025-12-09T08:41:48.333174Z","shell.execute_reply.started":"2025-12-09T08:41:48.328919Z","shell.execute_reply":"2025-12-09T08:41:48.332513Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"train,val -> processed img, label\n\ntrain loader, val loader wraps these datasets into iterable folders with batch size of 64 \n\ntraining data is shuffled for each epoch","metadata":{}},{"cell_type":"code","source":"train_ds = FERDataset(train_df, transform)\nval_ds   = FERDataset(val_df, transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=64, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:48.333736Z","iopub.execute_input":"2025-12-09T08:41:48.333931Z","iopub.status.idle":"2025-12-09T08:41:48.350941Z","shell.execute_reply.started":"2025-12-09T08:41:48.333917Z","shell.execute_reply":"2025-12-09T08:41:48.350222Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\nmodel = models.resnet18(weights=\"IMAGENET1K_V1\")\n\n# Replace FC layer\nmodel.fc = nn.Linear(512, 5)\n\n# Train only FC\nfor param in model.fc.parameters():\n    param.requires_grad = True\n\nmodel = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# -----------------------------\n# Loss & Optimizer\n# -----------------------------\ncriterion = nn.CrossEntropyLoss()\n\n# Adam optimizer with light weight decay for stability\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:48.351780Z","iopub.execute_input":"2025-12-09T08:41:48.352006Z","iopub.status.idle":"2025-12-09T08:41:49.223817Z","shell.execute_reply.started":"2025-12-09T08:41:48.351992Z","shell.execute_reply":"2025-12-09T08:41:49.223206Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 192MB/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef evaluate(loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return correct / total * 100\n\nEPOCHS = 15\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0\n\n    for imgs, labels in train_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    train_acc = evaluate(train_loader)\n    val_acc   = evaluate(val_loader)\n\n    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {running_loss:.3f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\ntorch.save(model.state_dict(), \"/kaggle/working/FER_resnet18_pretrained.pt\")\nprint(\"Saved FER pretrained model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T08:41:49.224623Z","iopub.execute_input":"2025-12-09T08:41:49.224920Z","iopub.status.idle":"2025-12-09T09:23:30.141826Z","shell.execute_reply.started":"2025-12-09T08:41:49.224895Z","shell.execute_reply":"2025-12-09T09:23:30.141000Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15 | Loss: 326.476 | Train Acc: 79.78% | Val Acc: 72.13%\nEpoch 2/15 | Loss: 209.324 | Train Acc: 89.40% | Val Acc: 71.95%\nEpoch 3/15 | Loss: 117.560 | Train Acc: 95.62% | Val Acc: 72.51%\nEpoch 4/15 | Loss: 46.908 | Train Acc: 97.44% | Val Acc: 72.17%\nEpoch 5/15 | Loss: 25.054 | Train Acc: 98.41% | Val Acc: 71.09%\nEpoch 6/15 | Loss: 20.019 | Train Acc: 98.44% | Val Acc: 70.75%\nEpoch 7/15 | Loss: 22.722 | Train Acc: 96.63% | Val Acc: 70.23%\nEpoch 8/15 | Loss: 27.768 | Train Acc: 97.63% | Val Acc: 72.25%\nEpoch 9/15 | Loss: 18.820 | Train Acc: 99.25% | Val Acc: 72.54%\nEpoch 10/15 | Loss: 12.717 | Train Acc: 99.22% | Val Acc: 73.07%\nEpoch 11/15 | Loss: 10.110 | Train Acc: 98.40% | Val Acc: 72.47%\nEpoch 12/15 | Loss: 21.598 | Train Acc: 98.53% | Val Acc: 72.95%\nEpoch 13/15 | Loss: 19.489 | Train Acc: 99.06% | Val Acc: 72.54%\nEpoch 14/15 | Loss: 10.439 | Train Acc: 99.49% | Val Acc: 73.10%\nEpoch 15/15 | Loss: 9.292 | Train Acc: 98.82% | Val Acc: 71.42%\nSaved FER pretrained model.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"raw","source":"","metadata":{"execution":{"iopub.status.busy":"2025-12-08T18:42:28.740763Z","iopub.status.idle":"2025-12-08T18:42:28.740943Z","shell.execute_reply.started":"2025-12-08T18:42:28.740857Z","shell.execute_reply":"2025-12-08T18:42:28.740867Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}